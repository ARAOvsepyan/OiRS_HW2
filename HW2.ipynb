{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Домашнее задание 2. Нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Овсепян Ара ИУ8-83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В зависимости от варианта, для решения задачи используйте следующие наборы данных:\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "         <tr>\n",
    "            <th colspan=1>Задача классификации</th>\n",
    "            <th colspan=5>Задача регрессии</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th> </th>\n",
    "            <th>A</th>\n",
    "            <th>B</th>\n",
    "            <th>C</th>\n",
    "            <th>D</th>\n",
    "            <th>E</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>K</td>\n",
    "            <td>1</td>\n",
    "            <td>2</td>\n",
    "            <td>3</td>\n",
    "            <td>4</td>\n",
    "            <td>5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>L</td>\n",
    "            <td>6</td>\n",
    "            <td>7</td>\n",
    "            <td>8</td>\n",
    "            <td style=\"background-color: green\">9</td>\n",
    "            <td>10</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>M</td>\n",
    "            <td>11</td>\n",
    "            <td>12</td>\n",
    "            <td>13</td>\n",
    "            <td>14</td>\n",
    "            <td>15</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>N</td>\n",
    "            <td>16</td>\n",
    "            <td>17</td>\n",
    "            <td>18</td>\n",
    "            <td>19</td>\n",
    "            <td>20</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>O</td>\n",
    "            <td>21</td>\n",
    "            <td>22</td>\n",
    "            <td>23</td>\n",
    "            <td>24</td>\n",
    "            <td>25</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Инициализация ноутбука\n",
    "\n",
    "\n",
    "Загрузка необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torch import FloatTensor\n",
    "from torch.nn import Module\n",
    "\n",
    "from torch import allclose\n",
    "from torch import from_numpy\n",
    "\n",
    "from math import sqrt                       \n",
    "from torch.nn.functional import mse_loss \n",
    "\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Linear\n",
    "\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Tanh\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import ELU\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.optim import RMSprop\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch.nn import Dropout\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Искусственная неронная сеть для решения задачи регрессии (9 баллов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE = 5800\n",
    "emoloyeeAttrition = pd.read_csv('../data/Employee-Attrition.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Загрузка данных\n",
    "\n",
    "\n",
    "Загрузите данные в датафрейм при помощи функции `read_csv` блиблиотеки pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/insurance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 График совместного распределения признаков\n",
    "\n",
    "\n",
    "Постройте график совместного распределения количественных признаков при помощи функции pairplot библиотеки seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Разделение набора данных на тренировочный и тестовый\n",
    "\n",
    "Разделите набор данных на тренировочный и тестовый в соотношении 80%/20% при помощи функции `train_test_split` библиотеки `sklearn.model_selection`. При необходимости категориальные признаки в числовые (например, при помощи функции `get_dummies` библиотеки pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, Test = train_test_split(pd.get_dummies(data), train_size=0.8,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Загрузите данные, поделить на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurances = pd.read_csv('./data/insurance.csv', sep=',')\n",
    "insurances = pd.get_dummies(insurances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = insurances.charges\n",
    "X = insurances.drop(columns='charges')\n",
    "\n",
    "X_scaled = StandardScaler(copy=True, with_mean=True, with_std=True).fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=69)\n",
    "\n",
    "print(X_train.head())\n",
    "print(Y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 По необходимости проведите преодбработку/нормализацию данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_train = FloatTensor(X_train.values)\n",
    "X_t_test  = FloatTensor(X_test.values )\n",
    "Y_t_train = FloatTensor(Y_train.values)\n",
    "Y_t_test  = FloatTensor(Y_test.values )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Попробуйте различное количество слоёв\n",
    "Обучите 4 модели, используя различное количество линейных слоёв: 1 (=линейная регрессия), 2, 3, 4. Между двумя линейными слоями должна быть фунция активации, например, сигмоида. На последнем слое функцию активации можно не использовать.\n",
    "\n",
    "Постройте: 1) график loss для train и test в зависимости от используемого количетсва слоёв; 2) график accuracy для train и test в зависимости от используемого количества слоёв."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_e = 0.0001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self, X, Y, a, l, f=ReLU, opt=Adam, lr=0.3, momentum=None):\n",
    "        super(Model, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = Y\n",
    "        self.attrs = a\n",
    "        self.amount = l\n",
    "        self.activ = f\n",
    "\n",
    "        self.batch = None\n",
    "        self.dropout = None\n",
    "\n",
    "        self.gen_layers()\n",
    "        self.opt = opt(self.conv.parameters(), lr=lr)\n",
    "        if momentum:\n",
    "            self.opt = opt(self.conv.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    def gen_layers(self):\n",
    "        self.conv = Sequential()\n",
    "\n",
    "        for i in range(self.amount):\n",
    "            if i == self.amount - 1:\n",
    "                self.conv.add_module(f'lin_{i+1}', Linear(self.attrs, 1))\n",
    "                continue\n",
    "            \n",
    "            self.conv.add_module(f'lin_{i+1}', Linear(self.attrs, self.attrs))\n",
    "            self.normalized(i)\n",
    "            self.conv.add_module(f'act_{i+1}', self.activ())\n",
    "\n",
    "    def normalized(self, i):\n",
    "        if self.dropout is not None:\n",
    "            self.conv.add_module(f'Drp_{i+1}', Dropout(p=self.dropout))\n",
    "\n",
    "        if self.batch is not None:\n",
    "            self.conv.add_module(f'Bth_{i+1}', BatchNorm1d(self.attrs))\n",
    "            \n",
    "    def batch_norm(self):\n",
    "        self.batch = True\n",
    "\n",
    "    def dropout(self, a):\n",
    "        self.dropout = a\n",
    "\n",
    "    def net(self,  X=None):\n",
    "        if X is None:\n",
    "            X = self.X\n",
    "            \n",
    "        return self.conv.forward(X)[:,0]\n",
    "\n",
    "    def loss(self, pred, Y=None):\n",
    "        if Y is None:\n",
    "            Y = self.y\n",
    "        return mse_loss(pred, Y)\n",
    "\n",
    "    def train(self, epochs=1000):\n",
    "        loss = []\n",
    "        accur = []\n",
    "        for _ in range(epochs):\n",
    "            self.opt.zero_grad()\n",
    "            self.conv.train()\n",
    "\n",
    "            pred = self.net()\n",
    "\n",
    "            loss = self.loss(pred)\n",
    "            loss.backward()\n",
    "\n",
    "            self.opt.step()\n",
    "            \n",
    "            loss.append(sqrt(loss.item()))\n",
    "\n",
    "            accuracy = (pred == self.y).float().sum()\n",
    "            accur.append(accuracy * 100 / pred.shape[0])\n",
    "\n",
    "            plt.yscale('log')\n",
    "\n",
    "        plt.plot(loss)\n",
    "        plt.show()\n",
    "        plt.plot(accur)\n",
    "        plt.show()\n",
    "\n",
    "        return accur\n",
    "    \n",
    "    def test(self, X, Y):\n",
    "        pred = self.net(X)\n",
    "        loss = self.loss(pred, Y)\n",
    "        ls = sqrt(loss.item())\n",
    "\n",
    "        print(f'Loss: {ls}')\n",
    "        \n",
    "        return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    model = Model(X_t_train, Y_t_train, len(X_train.columns), i+1, f=ReLU)\n",
    "    print(model)\n",
    "    model.train()\n",
    "    model.test(X_t_test, Y_t_test)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Попробуйте различные функции активации\n",
    "Обучите 4 модели, используя 4 различных функции активации: sigmoid, tanh, ReLU, ELU.\n",
    "\n",
    "Постройте: 1) график loss для train и test в зависимости от используемой функции активации; 2) график accuracy для train и test в зависимости от используемой функции активации;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_train, Y_train, len(X_train.columns), 4, Sigmoid)\n",
    "print(model)\n",
    "model.train()\n",
    "model.test(X_t_test, Y_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_t_train, Y_t_train, len(X_train.columns), 4, Tanh)\n",
    "print(model)\n",
    "model.train()\n",
    "model.test(X_t_test, Y_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_t_train, Y_t_train, len(X_train.columns), 4, ReLU)\n",
    "print(model)\n",
    "model.train()\n",
    "model.test(X_t_test, Y_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_t_train, Y_t_train, len(X_train.columns), 4, ELU)\n",
    "print(model)\n",
    "model.train()\n",
    "model.test(X_t_test, Y_t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Попробуйте различные алгоритмы оптимизации\n",
    "\n",
    "Обучите 4 модели, используя 4 различных алгоритма оптимизации: SGD, SGD with momentum, RMSprop, Adam\n",
    "\n",
    "Постройте: 1) график loss для train и test в зависимости от используемого алгоритма оптимизации; 2) график accuracy для train и test в зависимости от используемого алгоритма оптимизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_t_train, Y_t_train, len(X_train.columns), 4, ReLU, SGD, lr=0.000001)\n",
    "print(model)\n",
    "model.train()\n",
    "model.test(X_t_test, Y_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_t_train, Y_t_train, len(X_train.columns), 4, ReLU, SGD, lr=0.0001, momentum=0.04)\n",
    "print(model)\n",
    "model.train()\n",
    "model.test(X_t_test, Y_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_t_train, Y_t_train, len(X_train.columns), 4, ReLU, RMSprop)\n",
    "print(model)\n",
    "model.train()\n",
    "model.test(X_t_test, Y_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_t_train, Y_t_train, len(X_train.columns), 4, ReLU, Adam)\n",
    "print(model)\n",
    "model.train()\n",
    "model.test(X_t_test, Y_t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Попробуйте добавить dropout и batch norm\n",
    "\n",
    "Обучите 5 моделей, используя 5 различных конфигураций: только BatchNorm, только dropout 0.2, только dropout 0.5, BatchNorm + dropout 0.2, BatchNorm + dropout 0.5.\n",
    "\n",
    "Постройте: 1) график loss для train и test в зависимости от используемой конфигурации; 2) график accuracy для train и test в зависимости от используемой конфигурации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_t_train, Y_t_train, len(X_train.columns), 4)\n",
    "model.batch_norm()\n",
    "model.gen_layers()\n",
    "print(model)\n",
    "model.train()\n",
    "model.test(X_t_test, Y_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_t_train, Y_t_train, len(X_train.columns), 4)\n",
    "model.dropout(0.2)\n",
    "model.gen_layers()\n",
    "print(model)\n",
    "model.train()\n",
    "model.test(X_t_test, Y_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_t_train, Y_t_train, len(X_train.columns), 4)\n",
    "model.dropout(0.5)\n",
    "model.gen_layers()\n",
    "print(model)\n",
    "model.train()\n",
    "model.test(X_t_test, Y_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_t_train, Y_t_train, len(X_train.columns), 4)\n",
    "model.batch_norm()\n",
    "model.dropout(0.2)\n",
    "model.gen_layers()\n",
    "print(model)\n",
    "model.train()\n",
    "model.test(X_t_test, Y_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_t_train, Y_t_train, len(X_train.columns), 4)\n",
    "model.batch_norm()\n",
    "model.dropout(0.5)\n",
    "model.gen_layers()\n",
    "print(model)\n",
    "model.train()\n",
    "model.test(X_t_test, Y_t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Постройте финальную модель\n",
    "Используя информацию, полученную на предыдущих этапах, предложите оптимальную конфигурацию нейронной сети для вашей задачи. Обучите модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_t_train, Y_t_train, len(X_train.columns), 4, ReLU)\n",
    "print(model)\n",
    "model.train()\n",
    "model.test(X_t_test, Y_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fun(train, Train.charges, test, Test.charges)\n",
    "res_p = fun(train_proc, Train_proc.charges, test_proc, Test_proc.charges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('RMSE error')\n",
    "\n",
    "plt.plot(res[0], res[1], marker='o')\n",
    "plt.plot(res_p[0], res_p[1], marker='o')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Вывод\n",
    "\n",
    "Сравните качество (величину ошибки) для моделей из пп. 1.4-1.7. Какая модель показала наилучший результат?\n",
    "\n",
    "Для всех 3 типов моделей RMSE ошибка ниже порога Baseline только при исключении выбросов (> 77 процентиля) из набора данных.\n",
    "\n",
    "Сама же ошибка во всех трех случаях практически идентична (см. ниже).\n",
    "\n",
    "Из за возможности настройки параметров `alpha` и `solver` в `Ridge` и `Lasso`, следует предположить, что при других наборах параметров, эти методы дадут лучший резульат по сравнению с `LinearRegression`, из за отсутствия настройки таких доп. параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model\\t\\tRegular\\t\\tWith excluding\\n')\n",
    "for m, e in RES.items():\n",
    "    print(f'{m}\\t\\t{round(e[0], 2)}\\t\\t{round(e[1], 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Искусственная неронная сеть для решения задачи классификации (9 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Загрузите данные, поделить на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE = 0.70\n",
    "employee_Attrition = pd.read_csv('../data/Employee-Attrition.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 По необходимости проведите преодбработку/нормализацию данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_col = ['BusinessTravel','Department','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "dummy_attrition = pd.get_dummies(employee_Attrition, columns=dummy_col)\n",
    "\n",
    "dummy_attrition['Attrition'] = LabelEncoder().fit_transform(dummy_attrition['Attrition'])\n",
    "\n",
    "normal_attrition = pd.DataFrame(\n",
    "    StandardScaler().fit(dummy_attrition).transform(dummy_attrition),\n",
    "     columns=dummy_attrition.columns)\n",
    "\n",
    "train, test, train_attrition, test_attrition = train_test_split(\n",
    "    normal_attrition,\n",
    "    dummy_attrition.Attrition,\n",
    "    train_size=0.8,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "train_d = train.drop(columns='Attrition')\n",
    "test_d = test.drop(columns='Attrition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Попробуйте различное количество слоёв\n",
    "Обучите 4 модели, используя различное количество линейных слоёв: 1 (=логистическая регрессия), 2, 3, 4. Между двумя линейными слоями должна быть фунция активации, например, сигмоида. На последнем слое в качестве функции активации используйте сигмоиду.\n",
    "\n",
    "Постройте: 1) график loss для train и test в зависимости от используемого количетсва слоёв; 2) график accuracy для train и test в зависимости от используемого количества слоёв."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_layers(num, activationFunc= None):\n",
    "    layers = []\n",
    "\n",
    "    for layer in range(num):\n",
    "        if layer == num - 1:\n",
    "            layers.append(nn.Linear(55, 2))\n",
    "            layers.append(nn.LogSoftmax(dim=1))\n",
    "        else:\n",
    "            layers.append(nn.Linear(55, 55))\n",
    "            layers.append(activationFunc)\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(droppedValues, values, model):\n",
    "    predict = model.forward(torch.FloatTensor(droppedValues))\n",
    "    loss = functional.nll_loss(predict, torch.LongTensor(values))\n",
    "\n",
    "    return predict, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(data, predict):\n",
    "    return accuracy_score(data,np.argmax(predict.detach().numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, e):\n",
    "    loss_val = []\n",
    "    loss_val_test = []\n",
    "\n",
    "    acc_val = []\n",
    "    acc_val_test = []\n",
    "\n",
    "    for i in range(e):\n",
    "        optimizer.zero_grad()\n",
    "        model.train() \n",
    "\n",
    "        predict, loss = get_loss(test_d.values, train_attrition.values, model)\n",
    "        acc_val.append(score(train_attrition, predict))\n",
    "\n",
    "        predict_test, loss_test = get_loss(test_d.values, test_attrition.values, model)\n",
    "        loss_val_test.append(loss_test.item())\n",
    "        acc_val_test.append(score(test_attrition, predict_test))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val.append(loss.item())\n",
    "\n",
    "    plt.plot(loss_val)\n",
    "    plt.plot(loss_val_test)\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(acc_val_test)\n",
    "    plt.yscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(model, optimizer, epochs=1000):\n",
    "    train(model, optimizer, epochs)\n",
    "    test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    predict, loss = get_loss(test_d.values, test_attrition.values, model)\n",
    "\n",
    "    result = np.argmax(predict.detach().numpy(), axis=1)\n",
    "    f1 = f1_score(test_attrition, result, average='macro')\n",
    "    \n",
    "    print(classification_report(test_attrition, result, zero_division=0))\n",
    "    print(f'f1_score: {f1}')\n",
    "    print(f'loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Слои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Слой 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = gen_layers(1)\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слой 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = gen_layers(2, nn.ReLU())\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слой 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = gen_layers(3, nn.ReLU())\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слой 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = gen_layers(4, nn.ReLU())\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Попробуйте различные функции активации\n",
    "Обучите 4 модели, используя 4 различных функции активации на промежуточных слоях: sigmoid, tanh, ReLU, ELU. На выходном слое в качестве функции активации используйте сигмоиду.\n",
    "\n",
    "Постройте: 1) график loss для train и test в зависимости от используемой функции активации; 2) график accuracy для train и test в зависимости от используемой функции активации;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = gen_layers(4, nn.ReLU())\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = gen_layers(4, nn.ELU())\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ayers = gen_layers(4, nn.Sigmoid())\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = gen_layers(4, nn.Tanh())\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Попробуйте различные алгоритмы оптимизации\n",
    "Обучите 4 модели, используя 4 различных алгоритма оптимизации: SGD, SGD with momentum, RMSprop, Adam\n",
    "\n",
    "Постройте: 1) график loss для train и test в зависимости от используемого алгоритма оптимизации; 2) график accuracy для train и test в зависимости от используемого алгоритма оптимизации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = gen_layers(4, nn.Sigmoid())\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.SGD(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = gen_layers(4, nn.Sigmoid())\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = gen_layers(4, nn.Sigmoid())\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.RMSprop(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = gen_layers(4, nn.Sigmoid())\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Попробуйте добавить dropout и batch norm\n",
    "\n",
    "Обучите 5 моделей, используя 5 различных конфигураций: только BatchNorm, только dropout 0.2, только dropout 0.5, BatchNorm + dropout 0.2, BatchNorm + dropout 0.5.\n",
    "\n",
    "Постройте: 1) график loss для train и test в зависимости от используемой конфигурации; 2) график accuracy для train и test в зависимости от используемой конфигурации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbn(num, func = None, batch=55, dropout=0):\n",
    "    layers = []\n",
    "    for layer in range(num):\n",
    "        if layer == num - 1:\n",
    "            layers.append(nn.Linear(55, 2))\n",
    "            layers.append(nn.LogSoftmax(dim=1))\n",
    "        else:\n",
    "            layers.append(nn.Linear(55, 55))\n",
    "            if batch:\n",
    "                layers.append(nn.BatchNorm1d(batch))\n",
    "            if dropout:\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "            layers.append(func)\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = dbn(4, nn.Sigmoid())\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = dbn(4, nn.Sigmoid(), 0, 0.2)\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = dbn(4, nn.Sigmoid(), 0, 0.5)\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNorm + Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = dbn(4, nn.Sigmoid(), dropout=0.2)\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = dbn(4, nn.Sigmoid(), dropout=0.5)\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Постройте финальную модель\n",
    "Используя информацию, полученную на предыдущих этапах, предложите оптимальную конфигурацию нейронной сети для вашей задачи. Обучите модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = gen_layers(4, nn.Sigmoid())\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "train_test_model(model, torch.optim.Adam(model.parameters(), lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Выводы\n",
    "4-ех слойная модель с алгоритмом оптимизации Adam и функцией активацией Sigmoid показала самую высокую точность"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b65d6b6d7177b0379f8366a1ab651ff99d00da2da5f31146e28c8f64c25263c6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
